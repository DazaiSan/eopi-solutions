{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12: Hash Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "* Given a corpus of `n` words with `m` being the maximum length of any word, the list of anagrams can be generated in `O(nm)` time as below. The chances of overflow can be reduced by reducing the probability of `hash` being a large value. This can be done by assigning lower primes to the more frequently used characters. Also look at this [link](https://stackoverflow.com/questions/11108541/get-list-of-anagrams-from-a-dictionary). \n",
    "\n",
    "```\n",
    "procedure anagrams(corpus):\n",
    "    - dict := Empty HashMap\n",
    "    - For word in corpus:\n",
    "        - dict[anagram_hash(word)] := append \"word\"\n",
    "    - Return values of \"dict\" whose length is atleast 2\n",
    "    \n",
    "procedure anagram_hash(word):\n",
    "    - prime_array := array of the first 26 prime numbers\n",
    "    - hash := 1\n",
    "    - For char in word:\n",
    "        - hash := hash * (ascii(char) - ascii(`a`))\n",
    "    - Return hash\n",
    "```\n",
    "\n",
    "* `set.remove(x)` vs `set.discard(x)`? The former raises a `KeyError` if `x` is not in set. The latter returns `None` instead.\n",
    "\n",
    "* The built-in `hash()` function can greatly simplify the implementation of a hash function for a user-defined class i.e implementing `__hash__(self)`.\n",
    "\n",
    "* `frozenset` is hashable alternative to `set` if a collection of non-duplicate elements need to be hashed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1 Test for palindromic permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def can_form_palindrome(s):\n",
    "    \"\"\"\n",
    "    Returns True iff the given string is a palindrome\n",
    "    \"\"\"\n",
    "    return sum(v%2 for v in Counter(s).values()) <= 1\n",
    "\n",
    "# Tests\n",
    "assert not can_form_palindrome(\"hakuna\")\n",
    "assert can_form_palindrome(\"edified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.2 Is an anonymous letter constructible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_letter_constructible(letter, magazine):\n",
    "    \"\"\"\n",
    "    Returns True iff the given letter can be constructed from the given magazine\n",
    "    \"\"\"\n",
    "    letter_count = Counter(letter)\n",
    "    mag_count = Counter(magazine)\n",
    "    return not letter_count - mag_count\n",
    "    \n",
    "\n",
    "# Tests\n",
    "assert is_letter_constructible(\"hey\", \"hasenasdfy\")\n",
    "assert not is_letter_constructible(\"heyz\", \"hasenasdfy\")\n",
    "assert not is_letter_constructible(\"hhh\", \"hasdfas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_letter_constructible_2(letter, magazine):\n",
    "    letter_count = Counter(letter)\n",
    "    for c in magazine:\n",
    "        if c in letter_count:\n",
    "            letter_count[c] -= 1\n",
    "    return sum(v for v in letter_count.values() if v >= 0) == 0\n",
    "    \n",
    "    \n",
    "# Tests\n",
    "assert is_letter_constructible_2(\"hey\", \"hasenasdfy\")\n",
    "assert not is_letter_constructible_2(\"heyz\", \"hasenasdfy\")\n",
    "assert not is_letter_constructible_2(\"hhh\", \"hasdfas\")\n",
    "assert not is_letter_constructible_2(\"az\", \"aaay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.3 Implement an ISBN cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class ISBNCache:\n",
    "    def __init__(self, capacity):\n",
    "        self._cache = OrderedDict()\n",
    "        self._capacity = capacity\n",
    "        \n",
    "    def lookup(self, isbn):\n",
    "        if isbn not in self._cache:\n",
    "            raise KeyError(\"ISBN {} does not exist\".format(isbn))\n",
    "        # The below pop + insert operation, puts the key-value pair at the end of the OrderedDict\n",
    "        price = self._cache.pop(isbn)\n",
    "        self._cache[isbn] = price\n",
    "        return price\n",
    "    \n",
    "    def insert(self, isbn, price):\n",
    "        if isbn in price:\n",
    "            price = self._cache.pop(isbn)\n",
    "        elif len(self._cache) >= self._capacity:\n",
    "            # Remove LRU item. last = False assumes a FIFO ordering\n",
    "            self._cache.popitem(last=False)\n",
    "        self._cache[isbn] = price\n",
    "    \n",
    "    def delete(self, isbn):\n",
    "        return self._cache.pop(isbn, None) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic LRU Cache without using OrderedDict. \n",
    "# Other implementations: https://discuss.leetcode.com/topic/14591/python-dict-double-linkedlist/9\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, k, v):\n",
    "        self.key = k\n",
    "        self.val = v\n",
    "        self.prev = None\n",
    "        self.next = None\n",
    "\n",
    "class LRUCache:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.dic = dict()\n",
    "        self.prev = self.next = self\n",
    "        \n",
    "    def get(self, key):\n",
    "        if key in self.dic:\n",
    "            n = self.dic[key]\n",
    "            self._remove(n)\n",
    "            self._add(n)\n",
    "            return n.val\n",
    "        return -1\n",
    "\n",
    "    def put(self, key, value):\n",
    "        if key in self.dic:\n",
    "            self._remove(self.dic[key])\n",
    "        n = Node(key, value)\n",
    "        self._add(n)\n",
    "        self.dic[key] = n\n",
    "        if len(self.dic) > self.capacity:\n",
    "            n = self.next\n",
    "            self._remove(n)\n",
    "            del self.dic[n.key]\n",
    "\n",
    "    def _remove(self, node):\n",
    "        p = node.prev\n",
    "        n = node.next\n",
    "        p.next = n\n",
    "        n.prev = p\n",
    "\n",
    "    def _add(self, node):\n",
    "        p = self.prev\n",
    "        p.next = node\n",
    "        self.prev = node\n",
    "        node.prev = p\n",
    "        node.next = self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
